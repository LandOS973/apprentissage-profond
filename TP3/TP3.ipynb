{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TE2ItlsI956"
   },
   "source": [
    "# Deep Learning  \n",
    "\n",
    "\n",
    "## TP3 : Méthodologie, Expérimentations et Régularisation \n",
    "\n",
    "Sylvain Lamprier (sylvain.lamprier@univ-angers.fr)\n",
    "\n",
    "Supports adaptés de Nicolas Baskiotis (nicolas.baskiotis@sorbonne-univeriste.fr) et Benjamin Piwowarski (benjamin.piwowarski@sorbonne-universite.fr) -- MLIA/ISIR, Sorbonne Université"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:27:35.680376Z",
     "start_time": "2024-11-19T18:27:32.741999Z"
    }
   },
   "source": [
    "import torch\n",
    "print(\"La version de torch est : \",torch.__version__)\n",
    "print(\"Le calcul GPU est disponible ? \", torch.cuda.is_available())\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "## Chargement des données California_Housing et transformation en tensor.\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() ## chargement des données\n",
    "data_x = torch.tensor(housing['data'],dtype=torch.float)\n",
    "data_y = torch.tensor(housing['target'],dtype=torch.float).view(-1)\n",
    "Xdim = data_x.size(1)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La version de torch est :  2.5.1+cpu\n",
      "Le calcul GPU est disponible ?  False\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGIDLqItECDu"
   },
   "source": [
    "# Méthodologie expérimentale et boîte à outils\n",
    "Pytorch dispose d'un ensemble d'outils qui permettent de simplifier les démarches expérimentales. Nous allons voir en particulier : \n",
    "* le DataLoader qui permet de gérer le chargement de données, le partitionement et la constitution d'ensembles de test et d'apprentissage; \n",
    "* le checkpointing qui permet de sauvegarder/charger les modèles en cours d'entraînement.\n",
    "* le TensorBoard (qui vient de tensorflow) qui permet de suivre l'évolution en apprentissage de vos modèles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ4MoJP4k4i0"
   },
   "source": [
    "\n",
    "## DataLoader\n",
    "Le <a href=https://pytorch.org/docs/stable/data.html>**DataLoader**</a> et la classe associée <a href=https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset> **Dataset**</a>  permettent en particulier de :\n",
    "* charger des données\n",
    "* pré-processer les données\n",
    "* de gérer les mini-batchs (sous-ensembles sur lequel on effectue une descente de gradient).\n",
    "\n",
    "La classe **Dataset** est une classe abstraite qui nécessite l'implémentation que d'une seule méthode, ```__getitem__(self,index)``` : elle renvoie le i-ème objet du jeu de données (généralement un couple *(exemple,label)*. \n",
    "\n",
    "La classe **TensorDataset** est l'instanciation la plus courante d'un **Dataset**, elle permet de créer un objet **Dataset** à partir d'une liste de tenseurs qui renvoie pour un index $i$ donné le tuple contenant les $i$-èmes ligne de chaque tenseur.\n",
    "\n",
    "La classe **DataLoader** permet essentiellement de randomiser et de constituer des mini-batchs de façon simple à partir d'une instance de **Dataset**. Chaque mini-batch est constitué d'exemples tirés aléatoirement dans le **Dataset** passé en paramètre et mis bout à bout dans des tenseurs. La méthode ```collate_fn(*args)``` est utilisée pour cela (nous verrons une customization de cette fonction dans une séance ultérieure). C'est ce générateur qui est généralement parcouru lors de l'apprentissage à chaque itération d'optimisation.\n",
    "\n",
    "Voici un exemple de code pour utiliser le DataLoader : \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AZaWAFO8k8ze",
    "ExecuteTime": {
     "end_time": "2024-11-19T18:27:35.747670Z",
     "start_time": "2024-11-19T18:27:35.730380Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset, Dataset\n",
    "\n",
    "## Création d'un dataset à partir des deux tenseurs d'exemples et de labels\n",
    "train_data = TensorDataset(data_x,data_y)\n",
    "## On peut indexer et connaitre la longueur d'un dataset\n",
    "print(len(train_data),train_data[5])\n",
    "\n",
    "## Création d'un DataLoader\n",
    "## tailles de mini-batch de 16, shuffle=True permet de mélanger les exemples\n",
    "# loader est un itérateur sur les mini-batchs des données\n",
    "loader = DataLoader(train_data, batch_size=16,shuffle=True ) \n",
    "\n",
    "#Premier batch (aléatoire) du dataloader :\n",
    "print(len(iter(loader)),next(iter(loader)))\n",
    "\n",
    "## Exemple d'un Dataset (sans utilité dans le cas présent, TensorDataset permet de faire la même chose)\n",
    "class MyDataSet(Dataset):\n",
    "  def __init__(self, x,y):\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "  def __getitem__(self,i):\n",
    "    return self.x[i],self.y[i]\n",
    "  def __len__(self):\n",
    "    return len(self.x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640 (tensor([   4.0368,   52.0000,    4.7617,    1.1036,  413.0000,    2.1399,\n",
      "          37.8500, -122.2500]), tensor(2.6970))\n",
      "1290 [tensor([[ 4.5750e+00,  3.6000e+01,  4.9879e+00,  1.0393e+00,  1.0620e+03,\n",
      "          3.2085e+00,  3.7370e+01, -1.2198e+02],\n",
      "        [ 6.2560e+00,  3.6000e+01,  6.2591e+00,  1.0207e+00,  1.1150e+03,\n",
      "          2.8886e+00,  3.3820e+01, -1.1837e+02],\n",
      "        [ 4.0833e+00,  3.4000e+01,  7.0303e+00,  1.0341e+00,  5.4000e+02,\n",
      "          2.0455e+00,  3.4130e+01, -1.1832e+02],\n",
      "        [ 6.7718e+00,  1.9000e+01,  5.2512e+00,  1.0164e+00,  1.1580e+03,\n",
      "          2.7183e+00,  3.7360e+01, -1.2200e+02],\n",
      "        [ 4.0801e+00,  2.7000e+01,  5.1265e+00,  1.1352e+00,  1.2850e+03,\n",
      "          2.2270e+00,  3.7520e+01, -1.2228e+02],\n",
      "        [ 3.1406e+00,  4.3000e+01,  4.7159e+00,  1.0201e+00,  1.2990e+03,\n",
      "          2.9060e+00,  3.7760e+01, -1.2250e+02],\n",
      "        [ 3.5714e+00,  4.8000e+01,  5.9439e+00,  1.0312e+00,  7.8900e+02,\n",
      "          2.4579e+00,  3.5400e+01, -1.1899e+02],\n",
      "        [ 2.1375e+00,  3.9000e+01,  4.8835e+00,  1.0361e+00,  2.2560e+03,\n",
      "          3.1290e+00,  3.4130e+01, -1.1726e+02],\n",
      "        [ 2.6382e+00,  2.5000e+01,  6.0965e+00,  1.1314e+00,  1.7450e+03,\n",
      "          3.5832e+00,  3.8480e+01, -1.2147e+02],\n",
      "        [ 3.1200e+00,  5.2000e+01,  4.7975e+00,  1.0618e+00,  1.1570e+03,\n",
      "          1.7883e+00,  3.7840e+01, -1.2225e+02],\n",
      "        [ 2.9811e+00,  1.7000e+01,  5.7475e+00,  1.0281e+00,  1.8590e+03,\n",
      "          2.6073e+00,  3.4040e+01, -1.1771e+02],\n",
      "        [ 3.2636e+00,  2.2000e+01,  4.6250e+00,  1.0554e+00,  2.9010e+03,\n",
      "          3.1533e+00,  3.3780e+01, -1.1798e+02],\n",
      "        [ 4.4038e+00,  4.5000e+01,  4.5718e+00,  8.9443e-01,  8.9100e+02,\n",
      "          2.6129e+00,  3.3980e+01, -1.1836e+02],\n",
      "        [ 5.0145e+00,  2.1000e+01,  6.3108e+00,  1.0386e+00,  4.1990e+03,\n",
      "          2.7021e+00,  3.4230e+01, -1.1904e+02],\n",
      "        [ 3.9485e+00,  3.2000e+01,  4.5714e+00,  9.7403e-01,  5.6500e+02,\n",
      "          2.4459e+00,  3.3900e+01, -1.1835e+02],\n",
      "        [ 5.7780e+00,  1.6000e+01,  7.4137e+00,  1.0204e+00,  1.6730e+03,\n",
      "          3.1039e+00,  3.8370e+01, -1.2201e+02]]), tensor([2.1540, 3.6690, 5.0000, 3.6830, 3.9780, 3.1620, 0.8460, 0.8750, 0.7620,\n",
      "        2.4140, 2.3180, 1.8020, 2.5940, 2.4660, 2.3000, 1.7570])]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:28:37.103324Z",
     "start_time": "2024-11-19T18:27:35.843674Z"
    }
   },
   "source": [
    "EPOCHS = 100\n",
    "EPS=1e-4\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "optim = torch.optim.Adam(params=netSeq.parameters(),lr=EPS)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "# La boucle d'apprentissage :\n",
    "for i in range(EPOCHS):\n",
    "    cumloss = 0\n",
    "    # On parcourt tous les exemples par batch de 16 (paramètre batch_size de DataLoader)\n",
    "    for bx,by in loader:\n",
    "        loss = mseloss(netSeq(bx).view(-1),by)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        cumloss += loss.item()\n",
    "    if i % 10==0: print(f\"iteration : {i}, loss : {cumloss/len(loader)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 4.0722445338271385\n",
      "iteration : 10, loss : 1.3323838938114254\n",
      "iteration : 20, loss : 1.332155509882195\n",
      "iteration : 30, loss : 1.3319659058668816\n",
      "iteration : 40, loss : 1.3318969629300657\n",
      "iteration : 50, loss : 1.3318266125843508\n",
      "iteration : 60, loss : 1.3318087661913198\n",
      "iteration : 70, loss : 1.3317257170067278\n",
      "iteration : 80, loss : 1.3316943121972935\n",
      "iteration : 90, loss : 1.3316428315269855\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9x2LC_6lCQm"
   },
   "source": [
    "## Checkpointing\n",
    "Les modèles Deep sont généralement long à apprendre. Afin de ne pas perdre des résultats en cours de calcul, il est fortement recommander de faire du **checkpointing**, c'est-à-dire d'enregistrer des points d'étapes du modèle en cours d'apprentissage pour pouvoir reprendre à n'importe quel moment l'apprentissage du modèle en cas de problème.  Il s'agit en pratique de sauvegarder l'état du modèle et de l'optimisateur (et de tout autre objet qui peut servir lors de l'apprentissage) toutes les n itérations. Toutes les variables d'intérêt sont en général disponibles par la méthode **state_dict()** des modèles et de l'optimiseur. \n",
    "\n",
    "En pratique, vous pouvez utilisé un code dérivé de celui ci-dessous.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "URQTq8hrPJO0",
    "ExecuteTime": {
     "end_time": "2024-11-19T18:28:37.226029Z",
     "start_time": "2024-11-19T18:28:37.220418Z"
    }
   },
   "source": [
    "import os\n",
    "def save_state(epoch,model,optim,fichier):\n",
    "      \"\"\" sauvegarde du modèle et de l'état de l'optimiseur dans fichier \"\"\"\n",
    "      state = {'epoch' : epoch, 'model_state': model.state_dict(), 'optim_state': optim.state_dict()}\n",
    "      torch.save(state,fichier)\n",
    " \n",
    "def load_state(fichier,model,optim):\n",
    "      \"\"\" Si le fichier existe, on charge le modèle et l'optimiseur \"\"\"\n",
    "      epoch = 0\n",
    "      if os.path.isfile(fichier):\n",
    "          state = torch.load(fichier)\n",
    "          model.load_state_dict(state['model_state'])\n",
    "          optim.load_state_dict(state['optim_state'])\n",
    "          epoch = state['epoch']\n",
    "      return epoch\n",
    "\n",
    "fichier = \"/tmp/netSeq.pth\" \n",
    "save_state(EPOCHS,netSeq,optim,fichier)    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:29:14.189153Z",
     "start_time": "2024-11-19T18:28:37.241307Z"
    }
   },
   "source": [
    "# On crée un autre réseau similaire à celui sauvegardé et on charge les poids \n",
    "# on peut observer qu'on repart du même point que le réseau précédent\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "optim = torch.optim.Adam(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "start_epoch = load_state(fichier,netSeq,optim)\n",
    "for epoch in range(start_epoch,start_epoch+EPOCHS):\n",
    "    cumloss = 0\n",
    "    for bx,by in loader:\n",
    "        loss = mseloss(netSeq(bx).view(-1),by)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        cumloss += loss.item()\n",
    "    if epoch % 10 ==0: \n",
    "        save_state(epoch,netSeq,optim,fichier)\n",
    "        print(f\"epoch : {epoch}, loss : {cumloss/len(loader)}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thoma\\AppData\\Local\\Temp\\ipykernel_15760\\475055523.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(fichier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 100, loss : 1.3316494575535605\n",
      "epoch : 110, loss : 1.331620652257472\n",
      "epoch : 120, loss : 1.331537666662719\n",
      "epoch : 130, loss : 1.3315798090871915\n",
      "epoch : 140, loss : 1.3313185109995131\n",
      "epoch : 150, loss : 1.331292929945066\n",
      "epoch : 160, loss : 1.3313447450020517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m     optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     12\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 13\u001B[0m     \u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     cumloss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m: \n",
      "File \u001B[1;32m~\\Documents\\GitHub\\apprentissage-profond\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             )\n\u001B[1;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\apprentissage-profond\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\apprentissage-profond\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    211\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    213\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    214\u001B[0m         group,\n\u001B[0;32m    215\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    220\u001B[0m         state_steps,\n\u001B[0;32m    221\u001B[0m     )\n\u001B[1;32m--> 223\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\apprentissage-profond\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\apprentissage-profond\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 784\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\apprentissage-profond\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:379\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[0;32m    378\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mlerp_(grad, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n\u001B[1;32m--> 379\u001B[0m \u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad\u001B[38;5;241m.\u001B[39mconj(), value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[0;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m capturable \u001B[38;5;129;01mor\u001B[39;00m differentiable:\n\u001B[0;32m    382\u001B[0m     step \u001B[38;5;241m=\u001B[39m step_t\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IstQCvKblSvT"
   },
   "source": [
    "\n",
    "## GPU \n",
    "Afin d'utiliser un GPU lors des calculs, il est nécessaire de transférer les données et le modèle sur le GPU par l'intermédiaire de la fonction **to(device)** des tenseurs et des modules.  Il est impossible de faire une opération lorsqu'une partie des tenseurs sont sur GPU et l'autre sur CPU. Il faut que tous les tenseurs et paramètres soient sur le même device ! On doit donc s'assurer que le modèle, les exemples et les labels sont sur GPU pour faire les opérations.\n",
    "\n",
    "Par ailleurs, on peut connaître le device sur lequel est chargé un tenseur par l'intermédiaire de ```.device``` (mais pas pour un modèle, il faut aller voir les paramètres dans ce cas).\n",
    "\n",
    "Une manière simple d'utiliser un GPU quand il existe et donc d'avoir un code agnostique est la suivante : \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fs8s7EwwlWTn"
   },
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "loader = DataLoader(TensorDataset(data_x,data_y), batch_size=16,shuffle=True ) \n",
    "\n",
    "## On charge le modèle sur GPU\n",
    "## A faire avant la déclaration de l'optimiseur, sinon les paramètres optimisés ne seront pas les mêmes! \n",
    "\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "netSeq = netSeq.to(device)\n",
    "optim = torch.optim.Adam(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "for i,(bx,by) in enumerate(loader):\n",
    "    ## On charge le batch sur GPU\n",
    "    bx, by = bx.to(device), by.to(device)\n",
    "    loss = mseloss(netSeq(bx).view(-1),by)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "print(\"Device du mini-batch : \", bx.device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5J1b55_lFR-"
   },
   "source": [
    "\n",
    "## TensorBoard\n",
    "\n",
    "Durant l'apprentissage de vos modèles, il est agréable de visualiser de quelle manière évolue le coût, la précision sur l'ensemble de validation ainsi que d'autres éléments. TensorFlow dispose d'un outil très apprécié, le TensorBoard, qui permet de gérer très facilement de tels affichages. On retrouve tensorboard dans **Pytorch** dans ```torch.utils.tensorboard``` qui permet de faire le pont de pytorch vers cet outil. \n",
    "\n",
    "Le principe est le suivant :\n",
    "* tensorboard fait tourner en fait un serveur web local qui va lire les fichiers de log dans un répertoire local. L'affichage se fait dans votre navigateur à partir d'un lien fourni lors du lancement de tensorboard.\n",
    "* Les éléments que vous souhaitez visualiser (scalaire, graphes, distributions, histogrammes) sont écrits dans le fichier de log à partir d'un objet **SummaryWriter** .\n",
    "* la méthode ```add_scalar(tag, valeur, global_step)``` permet de logger une valeur à un step donné, ```add_scalar(tag, tag_scalar_dic, global_step)``` un ensemble de valeurs par l'intermédiaire du dictionnaire ```tag_scalar_dic``` (un regroupement des scalaires est fait en fonction du tag passé, chaque sous-tag séparé par un **/**).\n",
    "\n",
    "Il existe d'autres méthodes ```add_XXX``` pour visualiser par exemple des images, des histogrammes (cf <a href=https://pytorch.org/docs/stable/tensorboard.html>la doc </a>).\n",
    "\n",
    "Le code suivant illustre une manière de l'utiliser. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1kIhHDnElQd8"
   },
   "source": [
    "# Pour observer les courbes produites, il faut lancer tensorboard \n",
    "# à la main à partir du shell :  tensorboard --logdir /tmp/logs/deep\n",
    "TB_PATH = \"/tmp/logs/deep\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class DeuxCouches(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DeuxCouches,self).__init__()\n",
    "    self.un = torch.nn.Linear(Xdim,5)\n",
    "    self.act = torch.nn.Tanh()\n",
    "    self.deux = torch.nn.Linear(5,1)\n",
    "  def forward(self,x):\n",
    "    return self.deux(self.act(self.un(x)))\n",
    "\n",
    "EPS = 1e-5\n",
    "EPOCHS=100\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "netDeuxCouches = DeuxCouches()\n",
    "netSeq.name = \"Sequentiel\"\n",
    "netDeuxCouches.name = \"DeuxCouches\"\n",
    "## Obtention d'un SummaryWriter \n",
    "summary = SummaryWriter(f\"{TB_PATH}/test\")\n",
    "\n",
    "mseloss = torch.nn.MSELoss()\n",
    "for model in [netSeq, netDeuxCouches]:\n",
    "    optim = torch.optim.Adam(params=model.parameters(),lr=EPS) \n",
    "    for i in range(EPOCHS):\n",
    "        cumloss = 0\n",
    "        for boston_x, boston_y in loader:\n",
    "            loss = mseloss(model(boston_x),boston_y.view(-1,1))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()  \n",
    "            cumloss+= loss.item()\n",
    "        summary.add_scalar(f\"loss/{model.name}\",cumloss/len(loader),i)\n",
    "        print(f\"epoch : {i}, loss : {cumloss/len(loader)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualisation des courbes dans tensorboard\n",
    "![Capture du tensorboard](./img/tensorBoard1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaW5Av4elaBN"
   },
   "source": [
    "## Dernières remarques et exemple typique de code\n",
    "* Le graphe de calcul est instancié de manière dynamique sous pytorch, et cela consomme des ressources. Lorsqu'il n'y a pas de rétropropagation qui intervient - lors de l'évaluation d'un modèle par exemple -, il faut à tout prix éviter de le calculer. L'environnement **torch.no_grad()** permet de désactiver temporairement l'instanciation du graphe. **Toutes les procédures d'évaluation doivent se faire dans cet environnement afin d'économiser du temps !**\n",
    "* Pour certains modules, le comportement est différent entre l'évaluation et l'apprentissage (pour le dropout ou la batchnormalisation par exemple, ou pour les RNNs). Afin d'indiquer à pytorch dans quelle phase on se situe, deux méthodes sont disponibles dans la classe module,  **.train()** et **.eval()** qui permettent de basculer entre les deux environnements.\n",
    "\n",
    "Les deux fonctionalités sont très différentes : **no_grad** agit au niveau du graphe de calcul et désactive sa construction (comme si les variables avaient leur propriété **requires_grad** à False), alors que **eval/train** agissent au niveau du module et influence le comportement du module.\n",
    "\n",
    "Vous trouverez ci-dessous un exemple typique de code pytorch qui reprend l'ensemble des éléments de ce tutoriel. Vous êtes prêt maintenant à expérimenter la puissance de ce framework."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import os\n",
    "TB_PATH = \"/tmp/logs/module1\"\n",
    "MODEL_PATH = \"/tmp/models\"\n",
    "os.makedirs(MODEL_PATH,exist_ok=True)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b3TRg2p5ldCJ"
   },
   "source": [
    "def save_state(fichier,epoch,model,optim):\n",
    "    state = {'epoch' : epoch, 'model_state': model.state_dict(), 'optim_state': optim.state_dict()}\n",
    "    torch.save(state,fichier)\n",
    "\n",
    "def load_state(fichier,model,optim):\n",
    "    epoch = 0\n",
    "    if os.path.isfile(fichier):\n",
    "        state = torch.load(fichier)\n",
    "        model.load_state_dict(state['model_state'])\n",
    "        optim.load_state_dict(state['optim_state'])\n",
    "        epoch = state['epoch']\n",
    "    return epoch\n",
    "\n",
    "\n",
    "def train(model, loss, epochs, train_loader, test_loader,lr=1e-3):\n",
    "    # On créé un writer avec la date du modèle pour s'y retrouver\n",
    "    check_file = f\"{MODEL_PATH}/{model.name}.pth\"\n",
    "    summary = SummaryWriter(f\"{TB_PATH}/{model.name}\")\n",
    "    optim = torch.optim.Adam(params=model.parameters(),lr=lr)\n",
    "    start_epoch = load_state(check_file,model,optim)\n",
    "    for epoch in range(start_epoch,epochs):\n",
    "        # Apprentissage\n",
    "        # .train() inutile tant qu'on utilise pas de normalisation ou de récurrent\n",
    "        model.train()\n",
    "        cumloss = 0\n",
    "        for xbatch, ybatch in train_loader:\n",
    "            xbatch, ybatch = xbatch.to(device), ybatch.to(device)\n",
    "            outputs = model(xbatch)\n",
    "            l = loss(outputs.view(-1),ybatch)\n",
    "            optim.zero_grad()\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "            cumloss += l.item()\n",
    "        summary.add_scalar(\"loss/train\",  cumloss/len(train_loader),epoch)\n",
    "        print(f\"epoch : {epoch}, loss : {cumloss/len(train_loader)}\")\n",
    "        \n",
    "        if epoch % 10 == 0: \n",
    "            save_state(check_file,epoch,model,optim)\n",
    "            # Validation\n",
    "            # .eval() inutile tant qu'on utilise pas de normalisation ou de récurrent\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                cumloss = 0\n",
    "                for xbatch, ybatch in test_loader:\n",
    "                    xbatch, ybatch = xbatch.to(device), ybatch.to(device)\n",
    "                    outputs = model(xbatch)\n",
    "                    cumloss += loss(outputs.view(-1),ybatch).item()\n",
    "            summary.add_scalar(\"loss/validation\", cumloss/len(test_loader) ,epoch)\n",
    "            print(f\"epoch validation: {epoch}, loss : {cumloss/len(test_loader)}\")\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "# Datasets\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() ## chargement des données\n",
    "all_data = torch.tensor(housing['data'],dtype=torch.float)\n",
    "all_labels = torch.tensor(housing['target'],dtype=torch.float).view(-1)\n",
    "\n",
    "# Il est toujours bon de normaliser\n",
    "all_data = (all_data-all_data.mean(0))/all_data.std(0)\n",
    "all_labels = (all_labels-all_labels.mean())/all_labels.std()\n",
    "\n",
    "train_tensor_data = TensorDataset(all_data, all_labels)\n",
    "\n",
    "# Split en 80% apprentissage et 20% test\n",
    "train_size = int(0.8 * len(train_tensor_data))\n",
    "validate_size = len(train_tensor_data) - train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(train_tensor_data, [train_size, validate_size])\n",
    "\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "net = torch.nn.Sequential(torch.nn.Linear(all_data.size(1),5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "net.name = \"mon_premier_reseau_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "net = net.to(device)\n",
    "train(net,torch.nn.MSELoss(),EPOCHS,train_loader,valid_loader,lr=1e-5)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérimentations\n",
    "## Jeu de données MNIST\n",
    "Ce jeu de données est l'équivalent du *Hello world* en programmation. Chaque donnée est un chiffre manuscrit (de 0 à 9). Les lignes suivantes vous permettent de charger le jeu de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:29:36.868210Z",
     "start_time": "2024-11-19T18:29:36.259424Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "# deux couches caché de 100 neurones pour avoir le suraprentissage\n",
    "# l2 marche pas de ouf par contre dropout efficace\n",
    "# Modules (torch, nn, F et optim)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.functional import one_hot\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Progrès\n",
    "from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "#matpotlib \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tensorboard import notebook\n",
    "\n",
    "\n",
    "TB_PATH = \"/tmp/logs/deep_tp3\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "mean=[0.5]\n",
    "std=[0.5]\n",
    "batchsize=128\n",
    "\n",
    "#Transformations à appliquer sur le dataset (transformation des images en tenseurs et normalization pour obtenir des valeurs entre -1 et 1)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean, std)])\n",
    "\n",
    "# Téléchargement des données (via le dataset specifique MNIST de pytorch)\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "print(len(trainset))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, pin_memory=True, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize, pin_memory=True, shuffle=False)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thoma\\AppData\\Local\\Temp\\ipykernel_15760\\219069740.py:20: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation d'une image\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:29:45.041393Z",
     "start_time": "2024-11-19T18:29:44.905964Z"
    }
   },
   "source": [
    "def unnormalize(img):\n",
    "  if img.dim()==2 or ((img.dim()==3) and (img.size()[0]==1)):\n",
    "      return img*std[0]+mean[0]\n",
    "  return img * img.new(std).view(3, 1, 1) + img.new(mean).view(3, 1, 1)\n",
    "\n",
    "# Recuperation du premier batch\n",
    "imgs,labs=next(iter(trainloader))\n",
    "# dimension of images (flattened)\n",
    "HEIGHT,WIDTH = imgs.shape[2],imgs.shape[3] # taille de l'image\n",
    "\n",
    "INPUT_DIM = HEIGHT * WIDTH\n",
    "\n",
    "#Visualisation de la première image\n",
    "print(imgs.size())\n",
    "img = unnormalize(imgs[0]) # pour retrouver l'image d'origine (avant normalisation)\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img.squeeze(),cmap='Greys_r')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1658749e840>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:29:47.441115Z",
     "start_time": "2024-11-19T18:29:47.394061Z"
    }
   },
   "source": [
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset, Dataset\n",
    "\n",
    "## On utilise qu'une partie du training test pour mettre en évidence le sur-apprentissage\n",
    "TRAIN_RATIO = 0.01\n",
    "train_length = int(len(trainset)*TRAIN_RATIO)\n",
    "\n",
    "ds_train, ds_test =  torch.utils.data.random_split(trainset, (train_length, len(trainset)- train_length))\n",
    "\n",
    "#On utilise un DataLoader pour faciliter les manipulations, on fixe  la taille du mini batch à 300\n",
    "train_loader = DataLoader(ds_train,batch_size=300,shuffle=True)\n",
    "test_loader = DataLoader(ds_test,batch_size=300,shuffle=False)\n",
    "\n",
    "print(next(iter(train_loader)))\n",
    "def accuracy(yhat,y):\n",
    "    # y encode les indexes, s'assurer de la bonne taille de tenseur\n",
    "    assert len(y.shape)==1 or y.size(1)==1\n",
    "    return (torch.argmax(yhat,1).view(y.size(0),-1)== y.view(-1,1)).double().mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]]), tensor([4, 9, 5, 4, 9, 6, 7, 7, 4, 3, 0, 7, 2, 0, 6, 6, 1, 8, 9, 7, 8, 6, 1, 1,\n",
      "        1, 4, 0, 5, 4, 3, 3, 9, 0, 3, 8, 2, 9, 8, 5, 5, 6, 7, 8, 1, 6, 9, 1, 7,\n",
      "        0, 3, 8, 6, 9, 5, 9, 4, 4, 4, 3, 5, 5, 4, 7, 8, 8, 1, 3, 1, 3, 4, 0, 0,\n",
      "        7, 6, 1, 5, 3, 0, 6, 3, 7, 7, 9, 9, 3, 7, 2, 0, 0, 3, 7, 4, 9, 5, 2, 2,\n",
      "        7, 0, 9, 5, 4, 2, 0, 8, 2, 9, 5, 5, 6, 9, 8, 0, 4, 5, 8, 8, 5, 7, 0, 2,\n",
      "        4, 0, 7, 6, 8, 7, 7, 7, 9, 7, 1, 0, 7, 2, 7, 2, 0, 5, 9, 9, 4, 7, 1, 3,\n",
      "        7, 6, 9, 5, 2, 1, 7, 8, 1, 5, 0, 1, 6, 8, 2, 7, 0, 3, 1, 3, 6, 3, 8, 4,\n",
      "        5, 2, 3, 5, 3, 1, 7, 4, 4, 2, 8, 0, 8, 8, 8, 4, 9, 5, 9, 5, 2, 5, 9, 0,\n",
      "        4, 8, 8, 0, 3, 3, 8, 6, 7, 6, 6, 9, 1, 1, 1, 0, 5, 7, 6, 3, 1, 9, 5, 5,\n",
      "        3, 4, 8, 9, 8, 4, 4, 6, 6, 4, 9, 6, 7, 1, 8, 7, 9, 5, 8, 1, 2, 9, 2, 4,\n",
      "        7, 6, 4, 1, 1, 3, 1, 0, 3, 0, 4, 4, 1, 7, 4, 1, 7, 2, 4, 7, 8, 4, 7, 9,\n",
      "        6, 8, 8, 6, 6, 9, 7, 1, 0, 1, 2, 7, 4, 1, 6, 3, 4, 5, 7, 2, 9, 4, 9, 2,\n",
      "        1, 2, 6, 7, 9, 7, 3, 5, 7, 7, 6, 9])]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span class=\"alert-success\"> Exercice : Classification multi-labels, nombre de couches, fonction de coût </span>\n",
    "\n",
    "L'objectif est de classer chaque image parmi les 10 chiffres qu'ils représentent. Le réseau aura donc 10 sorties, une par classe, chacune représentant la probabilité d'appartenance à chaque classe. Pour garantir une distribution de probabilité en sortie, il faut utiliser le module <a href=https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html> **Softmax** </a> : $$\\texttt{Softmax}(\\mathbf{x})_i = \\frac{e^{x_i}}{\\sum_{j=1}^d x_j}$$ qui permet de normaliser le vecteur de sortie.\n",
    "\n",
    "* Faites quelques exemples de réseau à 1, 2, 3 couches et en faisant varier les nombre de neurones par couche. Utilisez un coût moindre carré dans un premier temps. Pour superviser ce coût, on doit construire le vecteur one-hot correspondant à la classe : un vecteur qui ne contient que des 0 sauf à l'index de la classe qui contient un 1 (utilisez ```torch.nn.functional.one_hot```).  Comparez les courbes de coût et d'erreurs en apprentissage et en test selon l'architecture.\n",
    "* Le coût privilégié en multi-classe est la *cross-entropy**. Ce coût représente la négative log-vraisemblance : $$NNL(y,\\mathbf{x}) = -x_{y} $$ en notant $y$ l'indice de la classe et $\\mathbf{x}$ le vecteur de log-probabilité inféré. On peut utiliser soit son implémentation par le module <a href=https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss>**NLLLoss**</a>, soit - plus pratique - le module <a href=https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>**CrossEntropyLoss** <a>  qui combine un *logSoftmax* et la cross entropie, ce qui évite d'avoir à ajouter un module de *Softmax* en sortie du réseau. Utilisez ce dernier coût et observez les changements.\n",
    "* Changez la fonction d'activation en une ReLU et observez l'effet."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-19T19:28:30.295086Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Fonction d'accuracy\n",
    "def accuracy(yhat, y):\n",
    "    assert len(y.shape) == 1 or y.size(1) == 1\n",
    "    return (torch.argmax(yhat, dim=1) == y).double().mean()\n",
    "\n",
    "def train_and_log(model, train_loader, test_loader, criterion, optimizer, epochs, writer):\n",
    "    for epoch in range(epochs):\n",
    "        # Mode entraînement\n",
    "        model.train()\n",
    "        train_loss, train_acc = 0, 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            # Aplatir les données si nécessaire\n",
    "            x_batch = x_batch.view(x_batch.size(0), -1)\n",
    "            \n",
    "            yhat = model(x_batch)\n",
    "            loss = criterion(yhat, y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += accuracy(yhat, y_batch).item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "\n",
    "        # Mode évaluation\n",
    "        model.eval()\n",
    "        test_loss, test_acc = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                # Aplatir les données si nécessaire\n",
    "                x_batch = x_batch.view(x_batch.size(0), -1)\n",
    "                \n",
    "                yhat = model(x_batch)\n",
    "                loss = criterion(yhat, y_batch)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                test_acc += accuracy(yhat, y_batch).item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader)\n",
    "\n",
    "        # Enregistrement dans TensorBoard\n",
    "        writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Test\": test_loss}, epoch)\n",
    "        writer.add_scalars(\"Accuracy\", {\"Train\": train_acc, \"Test\": test_acc}, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} -> Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Classe LinearMultiClass\n",
    "class LinearMultiClass(nn.Module):\n",
    "    def __init__(self, inSize, outSize, layers=[], finalActivation=None, activation=nn.Tanh):\n",
    "        super(LinearMultiClass, self).__init__()\n",
    "        # Construction des couches\n",
    "        all_layers = []\n",
    "        input_dim = inSize\n",
    "        # Ajouter les couches cachées\n",
    "        for hidden_dim in layers:\n",
    "            all_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            all_layers.append(activation())\n",
    "            input_dim = hidden_dim\n",
    "        # Ajouter la couche de sortie\n",
    "        all_layers.append(nn.Linear(input_dim, outSize))\n",
    "        # Ajouter la fonction d'activation finale si elle est définie\n",
    "        if finalActivation is not None:\n",
    "            all_layers.append(finalActivation())\n",
    "        # Utilisation de nn.Sequential pour empiler les couches\n",
    "        self.model = nn.Sequential(*all_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Comparaison des modèles\n",
    "def compare_models(train_loader, test_loader, input_dim, output_dim, epochs=10):\n",
    "    # Configurations à comparer\n",
    "    configs = [\n",
    "        {\"activation\": nn.Tanh, \"criterion\": nn.CrossEntropyLoss, \"tag\": \"Tanh_CrossEntropy\"},\n",
    "        {\"activation\": nn.ReLU, \"criterion\": nn.CrossEntropyLoss, \"tag\": \"ReLU_CrossEntropy\"},\n",
    "        {\"activation\": nn.Tanh, \"criterion\": nn.MSELoss, \"tag\": \"Tanh_MSE\"},\n",
    "        {\"activation\": nn.ReLU, \"criterion\": nn.MSELoss, \"tag\": \"ReLU_MSE\"},\n",
    "    ]\n",
    "    \n",
    "    for config in configs:\n",
    "        final_activation = nn.Softmax(dim=1)\n",
    "        # Initialisation du modèle\n",
    "        model = LinearMultiClass(\n",
    "        inSize=input_dim,\n",
    "        outSize=output_dim,\n",
    "        layers=[100, 100],\n",
    "        finalActivation=lambda: final_activation,\n",
    "        activation=config[\"activation\"]\n",
    "    )\n",
    "\n",
    "\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Initialisation de l'optimiseur et du critère\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = config[\"criterion\"]()\n",
    "        \n",
    "        # TensorBoard Writer\n",
    "        writer = SummaryWriter(log_dir=f\"runs/{config['tag']}\")\n",
    "        \n",
    "        print(f\"\\nTraining configuration: {config['tag']}\")\n",
    "        \n",
    "        # Entraînement\n",
    "        train_and_log(model, train_loader, test_loader, criterion, optimizer, epochs, writer)\n",
    "        \n",
    "        writer.close()\n",
    "\n",
    "# Paramètres du dataset et de l'entraînement\n",
    "input_dim = train_loader.dataset[0][0].numel()\n",
    "output_dim = 10  # Nombre de classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "compare_models(train_loader, test_loader, input_dim, output_dim, epochs=10)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training configuration: Tanh_CrossEntropy\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span class=\"alert-success\"> Exercice : Régularisation des réseaux </span>\n",
    "\n",
    "### Pénalisation des couches\n",
    "Une première technique pour éviter le sur-apprentissage est de régulariser chaque couche par une pénalisation sur les poids, i.e. de favoriser des poids faibles. On parle de pénalisation L1 lorsque la pénalité est de la forme $\\|W\\|_1$ et L2 lorsque la norme L2 est utilisée : $\\|W\\|_2^2$. En pratique, cela consiste à rajouter à la fonction de coût globale du réseau un terme en $\\lambda Pen(W)$ pour les paramètres de chaque couche que l'on veut régulariser.\n",
    "\n",
    "Expérimentez avec une norme L2 dans $\\{0,10^{-5},10^{-4},10^{-3},10^{-2},\\}$, l'évolution de la pénalisation et du coût en fonction du nombre d'époques. Vous pouvez aussi observer les histogrammes de la distribution des poids des différentes couches en utilisant la fonction addWeightsHisto ci dessous.  Utilisez pour ces experiences un réseau à 3 couches chacune de taille 100 et un coût de CrossEntropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# requiert que les modules soient enregistrés dans une liste model.layers\n",
    "def addWeightsHisto(writer,model,epoch):                \n",
    "    ix = 0\n",
    "    for module in model.layers:\n",
    "        if isinstance(module, nn.Linear):\n",
    "           writer.add_histogram(f'linear/{ix}/weight',module.weight, epoch)\n",
    "           ix += 1\n",
    "\n",
    "            \n",
    "## [[student]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [[/student]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Une autre technique très utilisée est le <a href=https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html> **Dropout** </a>. L’idée du Dropout est proche du moyennage de modèle : en entraînant k modèles de manière indépendante, on réduit la variance du modèle. Entraîner k modèles présente un surcoût non négligeable, et l’intérêt du Dropout est de réduire la complexité mémoire/temps de calcul. Le Dropout consiste à chaque itération à *geler* certains neurones aléatoirement dans le réseau en fixant leur sortie à zéro. Cela a pour conséquence de rendre plus robuste le réseau.\n",
    "\n",
    "Le comportement du réseau est donc différent en apprentissage et en inférence. Il est obligatoire d'utiliser ```model.train()``` et ```model.eval()``` pour différencier les comportements.\n",
    "Testez sur quelques réseaux pour voir l'effet du dropout."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## [[student]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [[/student]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm\n",
    "\n",
    "On sait que les données centrées réduites permettent un apprentissage plus rapide et stable d’un modèle ; bien qu’on puisse faire en sorte que les données en entrées soient centrées réduites, cela est plus délicat pour les couches internes d’un réseau de neurones. La technique de <a href=https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html> **BatchNorm**</a> consiste à ajouter une couche qui a pour but de centrer/réduire les données en utilisant une moyenne/variance glissante (en inférence) et les statistiques du batch (en\n",
    "apprentissage).\n",
    "\n",
    "Tout comme pour le dropout, il est nécessaire d'utiliser ```model.train()``` et ```model.eval()```. \n",
    "Expérimentez la batchnorm. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## [[student]]\n",
    "\n",
    "\n",
    "\n",
    "## [[/student]]\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLearning fc TP1 2020-2021-correction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
